{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1ErqeIF7PyaUsjOAE1aEKoZ_XBRjkdvrj",
      "authorship_tag": "ABX9TyOXR3cZ89saZj/pJV1uYtba",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaryaTereshchenko/AdClick/blob/main/ad_click.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.7"
      ],
      "metadata": {
        "id": "AgTVwUVx9PvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_IV6V4Py51GY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from pprint import pprint\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.layers import IntegerLookup, Concatenate, Flatten\n"
      ],
      "metadata": {
        "id": "du_2KSXV545J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "\n",
        "def download(url, file):\n",
        "    if not os.path.isfile(file):\n",
        "        print(\"Download file... \" + file + \" ...\")\n",
        "        urlretrieve(url,file)\n",
        "        print(\"File downloaded\")\n",
        "\n",
        "d10m_url = \"https://home.ipipan.waw.pl/sj/TIB_PAN_Adv/AdClick/D10M.tsv.gz\"\n",
        "download(d10m_url,'D10M.tsv.gz')\n",
        "print(\"All the files are downloaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eJFcqvK6Et0",
        "outputId": "410ed904-64f2-420c-f288-7b2b68689f6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All the files are downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d5m_url = \"https://home.ipipan.waw.pl/sj/TIB_PAN_Adv/AdClick/D5M_test_x.tsv.gz\"\n",
        "download(d5m_url,'D5M_test_x.tsv.gz')\n",
        "print(\"All the files are downloaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a05ZurkEu7b",
        "outputId": "d5fe3cc2-d312-4ced-94d3-52774702abc7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All the files are downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT_COLUMNS = [\"Position\", \"Age\", \"Depth\", \"Gender\", \"AdvertiserId\", \"AdDescription_tokens\", \"AdKeyword_tokens\", \"Query_tokens\", \"Click\"]\n",
        "DEFAULTS = [tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.string, tf.string, tf.string] "
      ],
      "metadata": {
        "id": "Y07znlppWs_i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = tf.data.experimental.make_csv_dataset(\"D5M_test_x.tsv.gz\",\n",
        "                                           field_delim=\"\\t\",\n",
        "                                           compression_type=\"GZIP\",\n",
        "                                           num_epochs=1,\n",
        "                                           column_defaults = DEFAULTS,\n",
        "                                           batch_size=1024,  \n",
        "                                           label_name=\"Click\",\n",
        "                                           select_columns= SELECT_COLUMNS,\n",
        "                                           shuffle=False, ignore_errors=True)"
      ],
      "metadata": {
        "id": "AzielUjBE90h"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(test_data.element_spec)"
      ],
      "metadata": {
        "id": "YQvXeZ-WWu45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.experimental.make_csv_dataset(\"D10M.tsv.gz\",\n",
        "                                           field_delim=\"\\t\",\n",
        "                                           compression_type=\"GZIP\",\n",
        "                                           num_epochs=1,\n",
        "                                           batch_size=1024,  \n",
        "                                           label_name=\"Click\",\n",
        "                                           select_columns= SELECT_COLUMNS,\n",
        "                                           shuffle=False)\n"
      ],
      "metadata": {
        "id": "BZLGJ_666HnP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(ds, ds_size=10000000, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "    \n",
        "    if shuffle:\n",
        "        # Specify seed to always have the same split distribution between runs\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds, test_ds"
      ],
      "metadata": {
        "id": "EV6a33P46KAG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(ds)"
      ],
      "metadata": {
        "id": "k2jXeIUD6Rpo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_ds.unbatch()\n",
        "\n",
        "needed_vocab = {\"AdKeyword_tokens\": [], \"AdDescription_tokens\": [], \"Query_tokens\": []}\n",
        "\n",
        "for dic in train.as_numpy_iterator():\n",
        "  for k, v in dic[0].items():\n",
        "    if k in needed_vocab.keys():\n",
        "      needed_vocab[k].append(v)"
      ],
      "metadata": {
        "id": "sPVwKMQvUBh9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_list(parameter):\n",
        "  list_of_tokens = list(map(lambda x: x.replace(b\"|\", b\" \").split(b\" \"), parameter))\n",
        "  flatten_list = [item for subl in list_of_tokens for item in subl]\n",
        "  return np.asarray(flatten_list)\n"
      ],
      "metadata": {
        "id": "d4OSsXyaUDnb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_tokens = transform_to_list(needed_vocab[\"AdKeyword_tokens\"])\n",
        "description_tokens = transform_to_list(needed_vocab[\"AdDescription_tokens\"])\n",
        "query_tokens = transform_to_list(needed_vocab[\"Query_tokens\"])\n",
        "total_vocab = np.unique(np.concatenate((keyword_tokens, description_tokens, query_tokens), axis=0))"
      ],
      "metadata": {
        "id": "oNMIbhsaUN9y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 128\n",
        "max_features = 221395 # max word number"
      ],
      "metadata": {
        "id": "j3cCxPEUUVu-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_on_slash(input_data):\n",
        "  return tf.strings.regex_replace(input_data, \"\\|\", \" \")"
      ],
      "metadata": {
        "id": "c7SnR-iDUYdC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  AUC SCORE 75.56%\n",
        "\"\"\"\n",
        "\n",
        "def build_model1():\n",
        "  inputs = {\n",
        "      \"Position\": Input(shape=(), dtype=tf.int32),\n",
        "      \"Age\": Input(shape=(), dtype=tf.int32),\n",
        "      \"Depth\": Input(shape=(), dtype=tf.int32),\n",
        "      \"Gender\": Input(shape=(), dtype=tf.int32),\n",
        "      \"AdvertiserId\": Input(shape=(), dtype=tf.int32),\n",
        "      \"Query_tokens\": Input(shape=(), dtype=tf.string),\n",
        "      \"AdDescription_tokens\": Input(shape=(), dtype=tf.string),\n",
        "      \"AdKeyword_tokens\": Input(shape=(), dtype=tf.string)}\n",
        "\n",
        "  # Integer part\n",
        "  input_age = IntegerLookup(vocabulary=[1,2,3,4,5,6], output_mode=\"one_hot\", num_oov_indices=0)(inputs[\"Age\"])\n",
        "  ci_p = IntegerLookup(vocabulary=[1,2,3], output_mode=\"one_hot\", num_oov_indices=0)(inputs[\"Position\"])\n",
        "  ci_d = IntegerLookup(vocabulary=[1,2,3], output_mode=\"one_hot\", num_oov_indices=0)(inputs[\"Depth\"])\n",
        "  ci_g = IntegerLookup(vocabulary=[0,1,2], output_mode=\"one_hot\", num_oov_indices=0)(inputs[\"Gender\"])\n",
        "  encoded = Concatenate()([ci_p, input_age, ci_d, ci_g])\n",
        "  layer = tf.keras.layers.Hashing(num_bins=128, output_mode=\"one_hot\")(inputs[\"AdvertiserId\"])\n",
        "  conc = tf.keras.layers.concatenate([layer, encoded])\n",
        "  num = Dropout(rate=0.3)(conc)\n",
        "  num = Dense(128)(num)\n",
        "  num = Flatten()(num)\n",
        "\n",
        "  # String part\n",
        "  description = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode=\"int\", pad_to_max_tokens=maxlen, standardize=split_on_slash, output_sequence_length=maxlen, vocabulary=total_vocab)(inputs[\"AdDescription_tokens\"])\n",
        "  x = tf.keras.layers.Embedding(max_features, output_dim=10, input_length=maxlen)(description)\n",
        "\n",
        "  query = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode=\"int\", pad_to_max_tokens=maxlen, standardize=split_on_slash, output_sequence_length=maxlen, vocabulary=total_vocab)(inputs[\"Query_tokens\"])\n",
        "  y = tf.keras.layers.Embedding(max_features, output_dim=10, input_length=maxlen)(query)\n",
        "\n",
        "  keywords = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode=\"int\", pad_to_max_tokens=maxlen, standardize=split_on_slash, output_sequence_length=maxlen, vocabulary=total_vocab)(inputs[\"AdKeyword_tokens\"])\n",
        "  o = tf.keras.layers.Embedding(max_features, output_dim=10, input_length=maxlen)(keywords)\n",
        "  \n",
        "  c = Concatenate()([x, y, o])\n",
        "  t = Dropout(rate=0.3)(c)\n",
        "  t = Dense(128)(t)\n",
        "  t = Flatten()(t)\n",
        "\n",
        "  z = Concatenate()([t, num])\n",
        "  z = tf.keras.layers.Dense(64, activation='relu')(z)\n",
        "  z = tf.keras.layers.BatchNormalization()(z)\n",
        "  z = tf.keras.layers.Dense(1, activation='sigmoid')(z)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=inputs, outputs=z)\n",
        "  model.compile(optimizer=\"Adam\", loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "          metrics=[\"AUC\"], run_eagerly=True)\n",
        "  return model"
      ],
      "metadata": {
        "id": "9Sk84-tn6TnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  AUC SCORE 77.48%\n",
        "\"\"\"\n",
        "def build_model2():\n",
        "  inputs = {\n",
        "      \"Position\": Input(shape=(), dtype=tf.int32),\n",
        "      \"Age\": Input(shape=(), dtype=tf.int32),\n",
        "      \"Depth\": Input(shape=(), dtype=tf.int32),\n",
        "      \"Gender\": Input(shape=(), dtype=tf.int32),\n",
        "      \"AdvertiserId\": Input(shape=(), dtype=tf.int32),\n",
        "      \"AdDescription_tokens\": Input(shape=(), dtype=tf.string),\n",
        "      \"Query_tokens\": Input(shape=(), dtype=tf.string),\n",
        "      \"AdKeyword_tokens\": Input(shape=(), dtype=tf.string)}\n",
        "\n",
        "  # Integer part\n",
        "  input_age = IntegerLookup(vocabulary=[1,2,3,4,5,6], output_mode=\"one_hot\", num_oov_indices=0)(inputs[\"Age\"])\n",
        "  ci_p = IntegerLookup(vocabulary=[1,2,3], output_mode=\"one_hot\", num_oov_indices=0)(inputs[\"Position\"])\n",
        "  ci_d = IntegerLookup(vocabulary=[1,2,3], output_mode=\"one_hot\", num_oov_indices=0)(inputs[\"Depth\"])\n",
        "  ci_g = IntegerLookup(vocabulary=[0,1,2], output_mode=\"one_hot\", num_oov_indices=0)(inputs[\"Gender\"])\n",
        "  encoded = Concatenate()([ci_p, input_age, ci_d, ci_g])\n",
        "  layer = tf.keras.layers.Hashing(num_bins=1024, output_mode=\"one_hot\")(inputs[\"AdvertiserId\"])\n",
        "\n",
        "  conc = tf.keras.layers.concatenate([layer, encoded])\n",
        "  num = Dropout(rate=0.3)(conc)\n",
        "  num = Dense(128)(num)\n",
        "  num = Flatten()(num)\n",
        "\n",
        "# String part\n",
        "  description = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode=\"int\", pad_to_max_tokens=maxlen, standardize=split_on_slash, output_sequence_length=maxlen, vocabulary=total_vocab)(inputs[\"AdDescription_tokens\"])\n",
        "  x = tf.keras.layers.Embedding(max_features, output_dim=10, input_length=maxlen)(description)\n",
        "  \n",
        "  title = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode=\"int\", pad_to_max_tokens=maxlen, standardize=split_on_slash, output_sequence_length=maxlen, vocabulary=total_vocab)(inputs[\"Query_tokens\"])\n",
        "  y = tf.keras.layers.Embedding(max_features, output_dim=10, input_length=maxlen)(title)\n",
        "\n",
        "  keywords = tf.keras.layers.TextVectorization(max_tokens=max_features, output_mode=\"int\", pad_to_max_tokens=maxlen, standardize=split_on_slash, output_sequence_length=maxlen, vocabulary=total_vocab)(inputs[\"AdKeyword_tokens\"])\n",
        "  o = tf.keras.layers.Embedding(max_features, output_dim=10, input_length=maxlen)(keywords)\n",
        "\n",
        "  c = Concatenate()([x, y, o])\n",
        "  c = tf.keras.layers.SpatialDropout1D(0.3)(c)\n",
        "  c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(c)\n",
        "  c = tf.keras.layers.GlobalAveragePooling1D()(c)\n",
        "  t = Dropout(rate=0.3)(c)\n",
        "  t = Flatten()(t)\n",
        "\n",
        "  z = Concatenate()([t, num])\n",
        "  z = tf.keras.layers.Dense(64, activation='relu')(z)\n",
        "  z = tf.keras.layers.BatchNormalization()(z)\n",
        "  z = tf.keras.layers.Dense(1, activation='sigmoid')(z)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=inputs, outputs=z)\n",
        "  model.compile(optimizer=\"Adam\", loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "          metrics=[\"AUC\"], run_eagerly=True)\n",
        "  return model"
      ],
      "metadata": {
        "id": "Cg4XOdp2l-zP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model2()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "S--6_wLR6ye_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, epochs=12, verbose=1, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmNEIBSR60hq",
        "outputId": "38d58188-7273-41ac-baad-7e5dc774baa5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "9766/9766 [==============================] - 1419s 127ms/step - loss: 0.1806 - auc: 0.6847\n",
            "Epoch 2/12\n",
            "9766/9766 [==============================] - 1241s 110ms/step - loss: 0.1724 - auc: 0.7253\n",
            "Epoch 3/12\n",
            "9766/9766 [==============================] - 1252s 110ms/step - loss: 0.1706 - auc: 0.7377\n",
            "Epoch 4/12\n",
            "9766/9766 [==============================] - 1250s 110ms/step - loss: 0.1693 - auc: 0.7459\n",
            "Epoch 5/12\n",
            "9766/9766 [==============================] - 1250s 110ms/step - loss: 0.1683 - auc: 0.7523\n",
            "Epoch 6/12\n",
            "9766/9766 [==============================] - 1242s 109ms/step - loss: 0.1674 - auc: 0.7574\n",
            "Epoch 7/12\n",
            "9766/9766 [==============================] - 1227s 108ms/step - loss: 0.1666 - auc: 0.7617\n",
            "Epoch 8/12\n",
            "9766/9766 [==============================] - 1228s 109ms/step - loss: 0.1660 - auc: 0.7653\n",
            "Epoch 9/12\n",
            "9766/9766 [==============================] - 1230s 109ms/step - loss: 0.1653 - auc: 0.7681\n",
            "Epoch 10/12\n",
            "9766/9766 [==============================] - 1226s 109ms/step - loss: 0.1647 - auc: 0.7708\n",
            "Epoch 11/12\n",
            "9766/9766 [==============================] - 1226s 108ms/step - loss: 0.1642 - auc: 0.7727\n",
            "Epoch 12/12\n",
            "9766/9766 [==============================] - 1225s 108ms/step - loss: 0.1638 - auc: 0.7748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f397892dc10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGfBzp6G7Hr7",
        "outputId": "b3f99c46-8b5b-49e5-9bb6-e7bea8e310e2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4883/4883 [==============================] - 291s 60ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('drive/MyDrive/results_Stetsenko.txt', 'w') as f:\n",
        "  for i in predict:\n",
        "    f.write(str(i))\n",
        "    f.write('\\n')\n",
        "f.close"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgzwkRM2P3vh",
        "outputId": "f2072427-cf04-4059-c673-15a3d5c38527"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close()>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5Qk0uKxOI7L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}